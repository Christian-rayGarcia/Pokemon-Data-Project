In our Pokemon data engineering project, we'll start by using Python to fetch information from an external API. We'll extract details such as name, types, stats, generation, and legendary status, and compile this data into a CSV file.

Azure Data Factory will then move this CSV file to Azure Blob Storage for secure and scalable storage. Next, we'll use Azure Databricks with PySpark for data transformation, including cleaning and restructuring, to prepare it for analysis.

Finally, we'll load the refined dataset into Azure Synapse Analytics to perform in-depth analyses with SQL queries, exploring trends, statistical distributions, and attribute correlations. This structured approach ensures a robust pipeline for handling Pokemon data, supporting analytics and potential advanced applications.

![FlowDiagram](https://github.com/Christian-rayGarcia/Pokemon-Data-Project/assets/47110238/9efdc47e-f6f5-4edb-97c8-dd51778522fb)
